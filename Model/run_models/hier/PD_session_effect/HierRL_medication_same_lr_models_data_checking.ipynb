{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e601d147",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import stan\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "sys.path.append('/mrhome/amingk/Documents/7TPD/ActStimRL')\n",
    "from Madule import utils\n",
    "import arviz as az\n",
    "from scipy import stats "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13386cf",
   "metadata": {},
   "source": [
    "### Action Learning Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "986914ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0\n",
      "(3445, 50000)\n",
      "Model 1\n",
      "(3445, 50000)\n",
      "Model 2\n",
      "(3445, 50000)\n",
      "Model 3\n",
      "(3445, 50000)\n",
      "Model 4\n",
      "(3445, 50000)\n",
      "Model 5\n",
      "(3445, 50000)\n",
      "Model 6\n",
      "(3445, 50000)\n",
      "Model 7\n",
      "(3445, 50000)\n"
     ]
    }
   ],
   "source": [
    "# select Act or Stim to model fit seperately\n",
    "cond_act_stim = 'Act'\n",
    "# read collected data across data\n",
    "behAll = pd.read_csv('/mnt/projects/7TPD/bids/derivatives/fMRI_DA/data_BehModel/originalfMRIbehFiles/AllBehData/behAll.csv')\n",
    "# select Action value learning and parkinsons disease\n",
    "behAll = behAll[(behAll['block']==cond_act_stim)&(behAll['patient']=='PD')]\n",
    "# the list of participant\n",
    "subList_PD = np.unique(behAll['sub_ID'])\n",
    "# number of models\n",
    "n_models =  8\n",
    "# declare waice variable\n",
    "log_waic_models = np.zeros(n_models)\n",
    "log_lppd_models = np.zeros(n_models)\n",
    "# loop over list of participants\n",
    "for m in range(n_models):\n",
    "    print(f'Model {m}')\n",
    "    # main directory of saving\n",
    "    mainScarch = '/mnt/scratch/projects/7TPD/amin/'\n",
    "    # pickle fine in the scratch folder\n",
    "    pickelDir = mainScarch  + 'realdata/hier/HierRL_' + str(cond_act_stim)+f'_medication_same_lr_model{m+1}.pkl'\n",
    "    \"\"\"Loading the pickle file of model fit from the subject directory\"\"\"\n",
    "    loadPkl = utils.load_pickle(load_path=pickelDir)\n",
    "    fit = loadPkl['fit'] \n",
    "    # get the linkelihood and comarision assessment       \n",
    "    log_lik = fit['log_lik']\n",
    "    print(log_lik.shape)\n",
    "    log_assessement = utils.waic(log_likelihood=log_lik)\n",
    "    log_waic_models[m] = log_assessement['waic']\n",
    "    log_lppd_models[m] = log_assessement['lppd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18991b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[66360.1 66358.4 66471.  67239.8 67333.6 67343.8 67234.7 66474.8]'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# waic meaure\n",
    "str(np.round(log_waic_models, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6e4e841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[22880.  22865.8 23030.3 23244.3 23438.5 23439.3 23232.9 23026. ]'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# waic lppd\n",
    "str(np.round(-log_lppd_models, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b627eee8",
   "metadata": {},
   "source": [
    "### Color Value learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "783102da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0\n",
      "(3451, 50000)\n",
      "Model 1\n",
      "(3451, 50000)\n",
      "Model 2\n",
      "(3451, 50000)\n",
      "Model 3\n",
      "(3451, 50000)\n",
      "Model 4\n",
      "(3451, 50000)\n",
      "Model 5\n",
      "(3451, 50000)\n",
      "Model 6\n",
      "(3451, 50000)\n",
      "Model 7\n",
      "(3451, 50000)\n"
     ]
    }
   ],
   "source": [
    "# select Act or Stim to model fit seperately\n",
    "cond_act_stim = 'Stim'\n",
    "# read collected data across data\n",
    "behAll = pd.read_csv('/mnt/projects/7TPD/bids/derivatives/fMRI_DA/data_BehModel/originalfMRIbehFiles/AllBehData/behAll.csv')\n",
    "# select Action value learning and parkinsons disease\n",
    "behAll = behAll[(behAll['block']==cond_act_stim)&(behAll['patient']=='PD')]\n",
    "# the list of participant\n",
    "subList_PD = np.unique(behAll['sub_ID'])\n",
    "# number of models\n",
    "n_models =  8\n",
    "# declare waice variable\n",
    "log_waic_models = np.zeros(n_models)\n",
    "log_lppd_models = np.zeros(n_models)\n",
    "# loop over list of participants\n",
    "for m in range(n_models):\n",
    "    print(f'Model {m}')\n",
    "    # main directory of saving\n",
    "    mainScarch = '/mnt/scratch/projects/7TPD/amin/'\n",
    "    # pickle fine in the scratch folder\n",
    "    pickelDir = mainScarch  + 'realdata/hier/HierRL_' + str(cond_act_stim)+f'_medication_same_lr_model{m+1}.pkl'\n",
    "    \"\"\"Loading the pickle file of model fit from the subject directory\"\"\"\n",
    "    loadPkl = utils.load_pickle(load_path=pickelDir)\n",
    "    fit = loadPkl['fit'] \n",
    "    # get the linkelihood and comarision assessment       \n",
    "    log_lik = fit['log_lik']\n",
    "    print(log_lik.shape)\n",
    "    log_assessement = utils.waic(log_likelihood=log_lik)\n",
    "    log_waic_models[m] = log_assessement['waic']\n",
    "    log_lppd_models[m] = log_assessement['lppd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09310453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[68448.  68430.6 68495.3 68763.9 68686.9 68791.4 68698.8 68457.6]'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# waic meaure\n",
    "str(np.round(log_waic_models, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2ba8c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[24699.4 24671.4 24717.7 24707.6 24668.7 24672.1 24708.5 24649.2]'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# waic lppd\n",
    "str(np.round(-log_lppd_models, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df1ee68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
