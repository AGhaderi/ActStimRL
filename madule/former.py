

def sample_Bernouli(theta = .5, n_samples = 1):
    """
    Generating samples at random from Bernouli density funtion
    """
    return (np.random.rand(n_samples) <= theta).astype(int)

def task_design_act_stim(subName ='sim-sub-001'):
    """
    This function performs the task desgin for Action an Stimulus Values learning
    as Probabilistic Reiforcement Learning task to test the relative contribution of
    Action and Rewarding mechanisms of Dopemiergic system in Parkinson disease.
    The experimental task design was predefined and stored in .mat files. Also, it is the same for all participants.
    There are two .m files, first is related to Action value learnig, when it is presented at the begining.
                            another is related to Stimulus value leanring, when it is presented at the begining.
    
    Arguments
    ----------
    firstAct: bool
        True if the task starts with with Action-value, False if the task sarts with Stimulus-value learning
        
    Output
    -------
    """
        
        
    """The action value learning is the first condition"""
    dataActFirst = loadmat('../data/predefined-task-design/ExpStruct_ActFirst_winOnly.mat')  
          
    # Two sessions, each session contains two runs
    session = np.repeat(1, 4*42)

    # Four runs, each run contains two blocks (conditions)
    run = np.concatenate([np.repeat(1, 2*42), #The session 1 and run 1
                          np.repeat(2, 2*42)])  #The session 1 and run 2

    # the number of trials for eigh conditions, each condition (Action value or Stimulus Value) includes 42 trials
    trialNumber = np.repeat(np.arange(1, 85), 2)
    
    # not perfectly counter-balance ledft and right stimulus response            
    yellowOnLeftSide = sample_Bernouli(n_samples=4*42)

    # not perfectly counter-balance ledft and right action response
    leftCanBePushed = sample_Bernouli(n_samples=4*42) 
                
    # Each block is Action value or Stimulus Value condition
    block = np.concatenate([np.repeat('Act', 42),  np.repeat('Stim', 42),
                            np.repeat('Stim', 42), np.repeat('Act', 42)])
    
    stimActFirst =  np.repeat('Act', 4*42)
        
         
    # Announce choice correct for push and Yellow
    pushCorrect = np.zeros(4*42).astype(int)
    yellowCorrect = np.zeros(4*42).astype(int)
    
    # predefined Yellow correct responce
    pushCorrect = np.concatenate([dataActFirst['triallist1_1'][0],       # The condition 1 and run 1
                                  sample_Bernouli(n_samples=42), # The condition 1 and run 2
                                  sample_Bernouli(n_samples=42), # The condition 2 and run 1
                                  dataActFirst['triallist2_2'][0]])      # The condition 2 and run 2
    # predefined Yellow correct responce
    yellowCorrect = np.concatenate([sample_Bernouli(n_samples=42), 
                                    dataActFirst['triallist1_2'][0],       
                                    dataActFirst['triallist2_1'][0],        
                                    sample_Bernouli(n_samples=42)])

    # winning reward for left and right side
    winAmtLeft = np.concatenate([leftCanBePushed[0*42:1*42]*dataActFirst['AmtList1_1'][0]+(1-leftCanBePushed[0*42:1*42])*(100-dataActFirst['AmtList1_1'][0]),
                                 yellowOnLeftSide[1*42:2*42]*dataActFirst['AmtList1_2'][0]+(1-yellowOnLeftSide[1*42:2*42])*(100-dataActFirst['AmtList1_2'][0]),
                                 leftCanBePushed[2*42:3*42]*dataActFirst['AmtList2_1'][0]+(1-leftCanBePushed[2*42:3*42])*(100-dataActFirst['AmtList1_1'][0]),
                                 yellowOnLeftSide[3*42:4*42]*dataActFirst['AmtList2_2'][0]+(1-yellowOnLeftSide[3*42:4*42])*(100-dataActFirst['AmtList1_2'][0])])           
    winAmtRight = 100 - winAmtLeft

    # winning amounts for Cplor respose
    winAmtYellow = yellowOnLeftSide*winAmtLeft + (1 - yellowOnLeftSide)*winAmtRight
    winAmtBlue = 100 - winAmtYellow     

    # winning amounts for pushed respose 
    winAmtPushable = leftCanBePushed*winAmtLeft + (1 - leftCanBePushed)*winAmtRight
    winAmtPullable = 100 - winAmtPushable

    # Dictionary of task desing generated by computer
    dataActDic = ({'session':session,
                    'run':run,
                    'stimActFirst':stimActFirst,
                    'block':block,
                    'trialNumber':trialNumber,
                    'yellowOnLeftSide':yellowOnLeftSide,
                    'leftCanBePushed':leftCanBePushed,
                    'winAmtLeft':winAmtLeft,
                    'winAmtRight':winAmtRight,
                    'winAmtYellow':winAmtYellow,
                    'winAmtBlue':winAmtBlue,
                    'winAmtPushable':winAmtPushable,
                    'winAmtPullable':winAmtPullable,
                    'pushCorrect':pushCorrect,
                    'yellowCorrect':yellowCorrect})
    dataAct = pd.DataFrame(dataActDic)  
    
    
    """The stimulus value learning is the first condition"""
    dataStimFirst = loadmat('../data/predefined-task-design/ExpStruct_StimFirst_winOnly.mat')
          
    # Two sessions, each session contains two runs
    session = np.repeat(2, 4*42)

    # Four runs, each run contains two blocks (conditions)
    run = np.concatenate([np.repeat(1, 2*42), #The session 1 and run 1
                          np.repeat(2, 2*42)])  #The session 1 and run 2

    # the number of trials for eigh conditions, each condition (Action value or Stimulus Value) includes 42 trials
    trialNumber = np.repeat(np.arange(1, 85), 2)
    
    # not perfectly counter-balance ledft and right stimulus response            
    yellowOnLeftSide = sample_Bernouli(n_samples=4*42)

    # not perfectly counter-balance ledft and right Stimulus response
    leftCanBePushed = sample_Bernouli(n_samples=4*42) 
                
    # Each block is Action value or Stimulus Value condition
    block = np.concatenate([np.repeat('Stim', 42),  np.repeat('Act', 42),
                            np.repeat('Act', 42), np.repeat('Stim', 42)])

    stimActFirst = np.repeat('Stim', 4*42)
        
         
    # Announce choice correct for push and Yellow
    pushCorrect = np.zeros(4*42).astype(int)
    yellowCorrect = np.zeros(4*42).astype(int)
    
    # predefined Yellow correct responce
    pushCorrect = np.concatenate([dataStimFirst['triallist1_1'][0],       # The condition 1 and run 1
                                  sample_Bernouli(n_samples=42), # The condition 1 and run 2
                                  sample_Bernouli(n_samples=42), # The condition 2 and run 1
                                  dataStimFirst['triallist2_2'][0]])      # The condition 2 and run 2
    # predefined Yellow correct responce
    yellowCorrect = np.concatenate([sample_Bernouli(n_samples=42), 
                                    dataStimFirst['triallist1_2'][0],       
                                    dataStimFirst['triallist2_1'][0],        
                                    sample_Bernouli(n_samples=42)])

    # winning reward for left and right side
    winAmtLeft = np.concatenate([leftCanBePushed[0*42:1*42]*dataStimFirst['AmtList1_1'][0]+(1-leftCanBePushed[0*42:1*42])*(100-dataStimFirst['AmtList1_1'][0]),
                                 yellowOnLeftSide[1*42:2*42]*dataStimFirst['AmtList1_2'][0]+(1-yellowOnLeftSide[1*42:2*42])*(100-dataStimFirst['AmtList1_2'][0]),
                                 yellowOnLeftSide[2*42:3*42]*dataStimFirst['AmtList2_2'][0]+(1-yellowOnLeftSide[2*42:3*42])*(100-dataStimFirst['AmtList2_2'][0]),
                                 leftCanBePushed[3*42:4*42]*dataStimFirst['AmtList2_1'][0]+(1-leftCanBePushed[3*42:4*42])*(100-dataStimFirst['AmtList2_2'][0])])           
    winAmtRight = 100 - winAmtLeft

    # winning amounts for Cplor respose
    winAmtYellow = yellowOnLeftSide*winAmtLeft + (1 - yellowOnLeftSide)*winAmtRight
    winAmtBlue = 100 - winAmtYellow     

    # winning amounts for pushed respose 
    winAmtPushable = leftCanBePushed*winAmtLeft + (1 - leftCanBePushed)*winAmtRight
    winAmtPullable = 100 - winAmtPushable

    # Dictionary of task desing generated by computer
    dataStimDic = ({'session':session,
                    'run':run,
                    'stimActFirst':stimActFirst,
                    'block':block,
                    'trialNumber':trialNumber,
                    'yellowOnLeftSide':yellowOnLeftSide,
                    'leftCanBePushed':leftCanBePushed,
                    'winAmtLeft':winAmtLeft,
                    'winAmtRight':winAmtRight,
                    'winAmtYellow':winAmtYellow,
                    'winAmtBlue':winAmtBlue,
                    'winAmtPushable':winAmtPushable,
                    'winAmtPullable':winAmtPullable,
                    'pushCorrect':pushCorrect,
                    'yellowCorrect':yellowCorrect})
    
    dataStim = pd.DataFrame(dataStimDic)
    
    
    # Dataframe of output
    output = pd.concat([dataAct, dataStim])
    
    # save task design
    parent_dir  = '../data/simulation/'
    if not os.path.isdir(parent_dir + subName):
        os.mkdir(parent_dir + subName)    
    output.to_csv('../data/simulation/' + subName +'/' +subName +'-task-design.csv', index=False)
    
    
    return output

